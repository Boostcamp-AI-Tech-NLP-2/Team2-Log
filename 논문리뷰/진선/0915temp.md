## 논문 [Attention is not explanation]

▶어제에 이어

▶Attention이 '설명력'이 있다라고 말하기 위해선 두 가지 조건 충족 요. 1) Attention weight는 feature importance를 측정하는 다양한 방법들과 상관관계가 있다. 2)Alternative(adversarial) attention weight는 예측 결과의 변화를 야기할 것이다. --> 다른 weight에 집중했다면, 결과는 달라야지. 그런데, 같네?

▶attention weight, input, output 간 관계를 중심으로 실험

▶Attention과 1) Gradient based feature importance 방법(τ_g), 2) feature들을 하나씩 제거할 때, model output의 변화(τ_loo) 간의 상관관계를 실험 -> 결론 : 문맥에 따라 표현이 바뀔 수 있는 단어가 있는 모델에서 Feature importance가 낮음

▶Adversarial 생성 1) 원래의 attention weight를 단순히 섞어 재배치 2) 원래의 distribution과 가장 다르지만 같은 결과를 도출하는 adversarial distribution을 직접 생성(노이즈 엄청 낀 이미지 같은) -> 표 해석 필요

---

## 논문 [Attention is not not explanation]

▶위 논문 '가정'에 의문 제기

▶실험 4개 1)simple frozen uniform weights baseline 2) a variance calibration based on multiple random seeds 3)diagnostic framework using frozen weights from pretrained models
4) end-to-end adversarial attention training protocol

▶1 : Attention weights 들을 유니폼으로 고정. 특정 데이터셋에선 유니폼도 학습된 모델처럼 좋은 성능이 나옴. 위 논문에서 두번째 실험, 랜덤 배치 변화량 관찰을 반박

▶2 : 학습 시퀀스를 랜덤으로 초기화, 분산 측정. adversarial distribution의 결과가 해석 불가능하다고 가정했던 부분을 반박

▶3 : 위 논문은 attention weights이 중요하지 않다고 했는데, 실험 결과 attention이 모델에 구애받지 않고 좋은 성능을 보임을 발견.

▶4 : adversarial distribution이 모델 분류 결과를 못 바꾼다는 내용에 대한 반박. 베이스 모델의 loss함수를 수정하고 adversarial distribution 학습. 결과적으로 전후 모델 정확도가 다름.

▶도식 이해 불가. 추가 설명 요.

---

## 논문 [GPT-1]

▶Pre-trained model의 시초격인 GPT-1

▶대부분 딥러닝 학습은 labeled된 데이터를 활용한 지도학습을 활용, 그러나 부족. 따라서 원본 텍스트를 활용하는 unsupervised learning이 가능한 모델이 필요하다.

▶Unlabeled text 퀘스트 : 이런 데이터에선 단어 수준 이상의 정보를 얻기가 쉽지 않고 어떤 optimization objective가 전이학습에 효과적인 representation을 배우는 데 효과적인지 알 수 없음(어떻게, 어떤 걸 학습해야 할지 모르겠음). 또 모델에서 학습된 표현(representation)을 다른 NLP task로 transfer하는데 가장 효율적인 방법이 정해지지 않음.

▶Unsupervised pre-training + Supervised fine-tuning = Semi-supervise

▶Stage : Unsupervised pre-training -> Supervised fine-tuning -> Final loss

▶LM으로 pre-training (transformer decoder 구조 사용) 만들어진 모델을 fine-tuning.

▶결과적으로 레이어 증가에 따른 정확도 상승을 목격, 12레이어에서 수렴. 모든 테스크에 대해 LSTM보다 더 높은 수치 기록.

▶기타 비교를 위한 실험: 1) pre trained이 없다면 있는것보다 성능 15% 하락. 2) fine tuning에서 LM목적함수를 제외하면 big dataset에서는 뱃, small에선 굿. 즉, 데이터셋이 적으면 LM성능을 기대하기 어려움. 3) LSTM과 성능 비교. 
