## 강의 [Transfomer]

▶ Self-Attension : Long-Term Dependency에서 발생하는 문제를 해결. Q, K, V. 

▶ Multi-Head Attention : 한 문장에 여러 구가 중첩될 때, 서로 다른 가중을 두어 해석. Self-Attension을 여러 개 쌓기.
Q and K의 연산만 가능하도록 사이즈가 구성되면 되지만, 일단 여기선 QKV 사이즈를 모두 동일하게 사용했다.

---------------------------------------------------------------------------------------

## 실습 [J-Notebook]

▶Multi-Head Attention : 가중 계산후 병합 과정. 병합은 concat. 일단 병렬 연산은 GPU만 충분하다면 빠르게 가능.

▶Masked Multi-Head Attention : Mask를 적용한 Multi-Head Attention 수행 과정.

---------------------------------------------------------------------------------------

## 참조 [Iilustrated Transformer]

▶자, 강의에 나왔던 걸 다시 한 번 훑어볼게. 기본적인 인코더 및 디코더 구성. 그리고 Self-attention이 어떻게 돌아가는가?

▶QKV계산 및 최종 가중벡터 출력법.

▶이미지가 강의와 동일.

▶Softmax(Q*K^T/sqrt(dk)) -> dk는 왜 나누나요 : 최종 값의 분산을 줄이자. 분산이 높으면(값이 많을 수록 덧셈 항이 많아지고 분산은 up) 특정 높은 값에 대해 softmax값이 쏠리는 경향이 발생 = 데이터 부정확.(강의에도 나온다.)

---------------------------------------------------------------------------------------

논문 [Attention Is All You Need]

▶#Sequence_transduction #encode_and_decode

▶Long-Term Dependency 해결. 입출력 시 모든 변수에 전역 의존. 즉 병렬화 가능. 성능? 좋아. -> 지금 다 이거 써!

▶기본 구조(Model Architecture) (image 01)

▶논문에서의 하이퍼 파라미터는 변동 가능. 일단 그대로 쓰자.

▶Encoder : n= 6. input에 들어간 후 나온 결괏값이 다음 층의 input으로. 각 층에는 Multi-Head Attention, Feed Forward 삽입. 2개의 sub-layers and residual connection. layer nomalization. 모델의 모든 레이어는 512 차원으로 임베딩.

▶Decoder : n = 6. residual connection and layter normalization 동일. 각 층에 masking 추가.

▶Multi-Head Attention, Masked~~ 강의와 동일.

▶계산값을 좀 볼까. Self-Attention = O(1)(GPU가 충분하다면 호로록), Recurrent = O(n)(순차로 실행해야해. 즉, 병렬 Nope)

▶단순 계산값 문제 뿐 아니라 기존 병렬 불가 구조에 비해 Self-Attention은 문장의 전체적 의미를 함께 고려 가능.(인풋이 전역이고 다의미로(Multi-Head)해석되니까)

---------------------------------------------------------------------------------------

## 논문 [Attention is not explanation]

▶Attention은 이름 그대로 어떤 단어의 정보를 얼마나 가져올 지 알려주는 직관적인 방법처럼 보입니다. Attention을 모델의 Output을 설명하는 데에 활용할 수 있을까요?

▶This 논문 세이 : Attention이 어떤 설명의 효과가 있는지 알아보려 했으나, 결론적으로 설명력을 갖지 못한다.

▶Attention이 설명력의 자질이 있다면 어떤 특성이 나타야 하는데 그것이 없으므로 모델을 설명할 수 없다.

▶여기서 설명력이 있다란? '어떤 단어에 집중하는지, 또 그 단어는 어떤 단어에 집중하는지를 추적하다보면 결론적으로 왜 이런 결과가 나왔는지에 대한 특성이 보일 것이다'

▶글 순서만 다른 같은 영화평, 결론은 같지만 그 추적 방식이 달랐다. (가중치를 둔 단어가 달랐다)

---------------------------------------------------------------------------------------

## 논문 [Attention is not not Explanation]

▶가지가지.. 위 논문 반박.

▶This 논문 세이 : 저 논문이 틀린 건 아닌데, 실험 핀트가 조금 어긋난 거 같아. 우리는 이렇게 생각해~.

▶'설명력'이라는 정의를 어떻게 내리냐에 따라서 대답이 달라질거야.
